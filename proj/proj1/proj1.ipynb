{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"proj1.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - SQL\n",
    "## Due Date: Wednesday, September 24, 5:00pm\n",
    "\n",
    "In this project, we will be working with SQL on the IMDb database.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Explore and extract relevant information from database with SQL functions\n",
    "- Perform data cleaning and transformation using string functions and regex\n",
    "- Use the cleaned data to run insightful analysis using joins and aggregations functions\n",
    "\n",
    "**Note:** If at any point during the project, the internal state of the database or its tables have been modified in an undesirable way (i.e. a modification not resulting from the instructions of a question), restart your kernel, clear output, and simply re-run the notebook as normal. This will shutdown your current connection to the database, which will prevent the issue of multiple connections to the database at any given point. When re-running the notebook, you will create a fresh database based on the provided Postgres dump.\n",
    "\n",
    "If you face slow kernel times or are unable to open your notebook, restart your server by going to File -> Hub Control Panel -> Stop My Server and then clicking Start My Server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics & Scoring Breakdown\n",
    "\n",
    "Please read the submission instructions carefully and double check that your submission is not throwing any errors. Please ensure that public tests pass upon submission. It is your responsibility to wait until the autograder finishes running. We will not be accepting regrade requests for submission issues.\n",
    "\n",
    "Each coding question has **both public tests and hidden tests**. Roughly 50% of your coding grade will be made up of your score on the public tests released to you, while the remaining 50% will be made up of unreleased hidden tests. **Free-response questions (marked 'm' in the table below) are manually graded.**\n",
    "\n",
    "You do not need to complete the main questions in numerical order. However, **subparts of a question often build on each other and should be completed in sequence** and **Question 3 must be completed before starting Question 4**.\n",
    "    \n",
    "|Question|Points|\n",
    "|---|---|\n",
    "|0|1|\n",
    "|1a|1|\n",
    "|1b|2|\n",
    "|1c|1|\n",
    "|1d|1|\n",
    "|2a|1|\n",
    "|2b|3|\n",
    "|2c|3|\n",
    "|3a|2|\n",
    "|3b|2|\n",
    "|3c|2|\n",
    "|3d|m: 1|\n",
    "|4a|2|\n",
    "|4b|m: 1|\n",
    "|5|2|\n",
    "|**Total**|25|\n",
    "\n",
    "**Summary:** 25 points (autograded: 23, manual: 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration and Inegrity\n",
    "\n",
    "This is an **individual project**. However, you’re welcome to collaborate with any other student in the class as long as it’s within the [academic honesty guidelines](https://data101.org/fa25/syllabus/#collaboration-and-integrity).\n",
    "\n",
    "**We ask that you list any collaborators and outside sources in the cells below.** You are expected to fill this out honestly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborators:\n",
    "\n",
    "Please include the first and last names of the other Data 101 students you work with on this project below.\n",
    "- ex. Vicky Huang\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outside Sources:\n",
    "\n",
    "Please include the names and urls of any outside sources you reference for this project below.\n",
    "-  ex. [SQL Help!](https://www.youtube.com/watch?v=dQw4w9WgXcQ)\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before You Start: Assignment Tips\n",
    "\n",
    "\n",
    "<p><b>Please Read!</b> In this project we will assume you have attended lecture and seen how to connect to a Postgres server via two ways: JupySQL in Jupyter Notebook, and the psql command-line program (CLI).</p>\n",
    "\n",
    "    \n",
    "We have written up these instructions for you in the <a href=\"https://data101.org/fa25/assignment-tips/\">Fall 2025 Assignment Tips</a>—a handy resource that has many other tips that we **highly recommend** taking a moment to read through to save you time and improve your workflow:\n",
    "\n",
    "* PostgreSQL documentation\n",
    "* JupySQL and magic commands in Jupyter\n",
    "* JupyterHub keyboard shortcuts\n",
    "* psql and common meta-commands\n",
    "* Debugging:\n",
    "    * Where to create new cells to play nice with the autograder\n",
    "    * Opening/closing connections, deleting databases if all else fails\n",
    "* Local installation (not supported by staff officially, but for your reference)\n",
    "\n",
    "In Jupyter Notebooks, a [cell 'magic' command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) is a special command that is preceded by two percentage signs (%%). Cell magics operate on entire cells and are used to change the behavior of the entire cell. They are not part of the Python language itself but are specific to the Jupyter environment. They help us do a lot of cool things, like run SQL commands directly within Jupyter! For some questions with cell magic, we will be saving the literal query string with [query snippets](https://jupysql.ploomber.io/en/latest/api/magic-snippets.html) using `--save`, as illustrated below:\n",
    "\n",
    "```\n",
    "%%sql --save query_result << \n",
    "SELECT * FROM table ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Setup\n",
    "We are going to be using the `JupySQL` library to connect our notebook to a PostgreSQL database server on your JupyterHub account. Running the next cell will do so; you should not see any error messages after it executes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you are running this cell, you may need to run the following line as: %load_ext sql \n",
    "%reload_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we will unzip the data. This only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -u data/imdbdb.zip -d data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "**Create the `imdb` database**: <br>\n",
    "We will use PostgreSQL commands to create a database and import our data into it. Run the following cell to do this.\n",
    "* You can also run these cells in the command-line via `psql`.\n",
    "* If you run into the **role does not exist** error, feel free to ignore it. It does not affect data import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!psql postgresql://jovyan@127.0.0.1:5432/imdb -c 'SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE datname = current_database()  AND pid <> pg_backend_pid();'\n",
    "!psql postgresql://jovyan@127.0.0.1:5432/postgres -c 'DROP DATABASE IF EXISTS imdb'\n",
    "!psql postgresql://jovyan@127.0.0.1:5432/postgres -c 'CREATE DATABASE imdb'\n",
    "!psql postgresql://jovyan@127.0.0.1:5432/imdb -f data/imdbdb.sql -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to `imdb` database in the Notebook**: \n",
    "<br>\n",
    "Now let's connect to the new database we just created! There should be no errors after running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://jovyan@127.0.0.1:5432/imdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to `imdb` database in `psql`**: \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Do the following in a Terminal window!</b> (To open a Terminal in DataHub, go to File -> New -> Terminal.)\n",
    "</div>\n",
    "\n",
    "Connect to the same database via `psql`. See the [Fall 2025 Assignment Tips](https://data101.org/fa25/assignment-tips/#psql-the-postgressql-interactive-cli) website resource for details on connecting. Being able to read and implement written instructions is important and crucial in working as a data engineer! To connect to the database, you should be typing in a command into your JupyterHub Terminal. Once successfully connected, you should see ``imdb=# ``\n",
    "\n",
    "Once connected, run the following meta-command in the `psql` client:\n",
    "\n",
    "``\n",
    "\\l\n",
    "``\n",
    "\n",
    "This should display all databases on this server, including the `imdb` database you just created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Quick check**: To make sure things are working, let's fetch 10 rows from one of our tables `cast_sample`. Just run the following cell, no further action is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "  FROM cast_sample\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting the grader\n",
    "# Just run the following cell, no further action is needed.\n",
    "from data101_utils import GradingUtil\n",
    "grading_util = GradingUtil(\"proj1\")\n",
    "grading_util.prepare_autograder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `imdb` Database\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Read this entire section!</b> Understanding the schema is critical to doing the project correctly.\n",
    "</div>\n",
    "\n",
    "In this project, we are working with a reduced version of the [Internet Movie Database (IMDb)](https://www.imdb.com/) database. This Postgres database is a small random sample of actors from the much larger full database (which is over several GBs large) and includes their corresponding movies and cast info. Disclaimer: as a result, we may obtain wildly  different results than if we were to use the entire database. \n",
    "\n",
    "Below is a list of the relations in our database. Please carefully take the time to understand the references between each relations, as this will be important when querying from these relations.  \n",
    "- **actor_sample**: information about the actors including id, name, and gender\n",
    "- **cast_sample**: each person on the cast of each movie gets a row including cast id, each person's `id` (`actor_sample.id`), movie id (`movie_sample.id`), and role id (`role_type.id`)\n",
    "- **movie_sample**: sample of movies the actors have been in, including movie id, title, and the production year\n",
    "- **movie_info_sample**: this table originally had a lot of information for each movie (take a look at info_type to see the information available), but we have dropped some information to make it easier to manage. This table includes movie info's id, movie id, info type id, and the info itself\n",
    "- **info_type**: reference table to match each info type id to the description of the type of information\n",
    "- **role_type**: reference table for cast_sample to match role id to the description of the role\n",
    "\n",
    "Here's an exercise for you to think about: what meta-command (in terminal/CLI) returns this bolded list?\n",
    "\n",
    "### Key Notes\n",
    "- This database is **not** the same as the IMDb lecture database, but has a lot of of similar features. \n",
    "- Point of confusion: `movie_sample` and `actor_sample` both have attributes `id` corresponding to 7 digit unique numeric identifiers, but do **not** refer to the same data values.\n",
    "- `cast_sample` is analagous to the `crew` table from lecture. It can be used to match an actor's id to movies they have acted in, among other relations.\n",
    "- You are highly encouraged to spend some time exploring the metadata of these tables using Postgres meta-commands to better understand the data given and the relations between tables. To get started, try outputting the schema of the tables.\n",
    "- You may create unlimited CTEs, but **please do not create intermediate views** unless explicitly asked to because they may take up significant space and use up your allocated memory.\n",
    "- When querying the tables from the terminal using `psql`, ensure you end every query with a semicolon (`;`). For example, to select everything from the `movie_sample` table, run `SELECT * FROM movie_sample;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Question 0: Information Schema\n",
    "There are many metadata tables that Postgres updates for us, and the full list is in the Postgres documentation [(Chapter 35)](https://www.postgresql.org/docs/current/information-schema.html).\n",
    "\n",
    "For now, let’s look at the `.tables` table [(35.54)](https://www.postgresql.org/docs/current/infoschema-tables.html), which lists all the tables located in the database. For more information on information_schema please read the [course notes on PostgreSQL Schemas](https://data101.org/notes/3-query_perf/schemas.html#postgresql-schemas). Write a query that returns all rows referring to the six tables we described above in our `imdb` database. \n",
    "\n",
    "**Hints:**\n",
    "* What `table_schema` do these `imdb` data tables belong to?\n",
    "* Try writing a `SELECT` query that queries from `information_schema.tables`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_0 result_0 <<\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_0 = %sqlcmd snippets query_0\n",
    "grading_util.save_results(\"result_0\", query_0, result_0)\n",
    "result_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Question 1: Exploratory Data Analysis\n",
    "One of the first things you'll want to do with a database table is get a sense for its metadata: column names and types, and number of rows. \n",
    "\n",
    "## Question 1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We can use the PostgreSQL `\\d` meta-command to get a description of the `movie_info_sample` schema. Open up a terminal window, connect to the imdb server, and analyze the output of the meta-command: ``\\d movie_info_sample``. This should be very similar to what you did in the Database Setup section near the top of this project notebook.\n",
    "\n",
    "\n",
    "There are four attributes in this schema, of which `id` is one. What are the other attribute names? Assign `result_1a` to a list of strings, where each element is an attribute name. The list does not need to be in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "result_1a = [\"id\", ..., ..., ...]\n",
    "result_1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Debugging tip**: Throughout this project and when working with databases, you should always be checking schemas via the `\\d` psql metacommand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Next, let’s continue with our initial exploration of this table. How many rows are in this table? \n",
    "\n",
    "Assign `result_1b` to the result of a SQL query to calculate the number of rows in the `movie_info_sample` table.\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- Your query result should have exactly one row and one attribute; the lone value in the instance should be the number of rows:\n",
    "\n",
    "| count |\n",
    "| ----- |\n",
    "| SOME_INTEGER |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_1b result_1b <<\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_1b = %sqlcmd snippets query_1b\n",
    "grading_util.save_results(\"result_1b\", query_1b, result_1b)\n",
    "display(result_1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1c: Random table sample\n",
    "\n",
    "Now that we know a bit about the metadata of the table, let's randomly sample rows from `movie_info_sample` to explore its contents.\n",
    "\n",
    "Given that you know the size of the table from the previous query, **write a query that retrieves 5 tuples on expectation using the `BERNOULLI` sampling method.** That is, if we run the query multiple times, we should get 5 tuples on *average* in our resulting table. The `BERNOULLI` sampling method scans the whole table and selects individual rows independently with `p%` probability. Please see the [course notes on sampling](https://data101.org/notes/1-SQL/truncation.html#sampling) for syntax.\n",
    "\n",
    "Assign `p_1c` to a sampling rate that you pass into the `query_1c` f-string using Python variable substitution. Your formula should contain `count_1b`, which is the number of rows in the table.\n",
    "\n",
    "If Python variable substitution is done correctly, we should be able to change our `p%` probability by simply reassigning `p_1c` and rerunning the query. (For submission please leave `p_1c` unchanged.)\n",
    "\n",
    "We have also completed the SQL line magic for you; this references the Python f-string `query_1c` you created within a SQL query using JupySQL-specific syntax.\n",
    "\n",
    "Once you have completed the query, try running the SQL cell many times, and see what you notice.\n",
    "\n",
    "\n",
    "**Hints:**\n",
    "* Don't forget to express `p_1c` in units of percent, i.e., if you want to assign it to a value of 3%, you should do `p_1c = 3` not `p_1c = 0.03`\n",
    "* For a refresher on f-strings and Python variable substitution, see [this tutorial](https://www.geeksforgeeks.org/formatted-string-literals-f-strings-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "query_1b, result_1b_df = grading_util.load_results(\"result_1b\")\n",
    "count_1b = result_1b_df.iloc[0, 0]\n",
    "p_1c = ...\n",
    "# edit this query string using variable substitution and your defined p_1c\n",
    "query_1c_str = f\"\"\"SELECT * FROM movie_info_sample TABLESAMPLE ...\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_1c result_1c <<\n",
    "{{query_1c_str}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_1c = %sqlcmd snippets query_1c\n",
    "grading_util.save_results(\"result_1c\", query_1c, result_1c)\n",
    "result_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 1d: Random sample, fixed number of rows\n",
    "\n",
    "If a random number of rows is not of importance, a more efficient way to get some arbitrary tuples from a table is to use the `ORDER BY` and `LIMIT` clauses. In the next cell, fetch 5 **random** tuples from `movie_info_sample`. Compared to the previous question, your query result here should always have 5 tuples!\n",
    "\n",
    "**Hint**: Check out the [course notes on sampling](https://data101.org/notes/1-SQL/truncation.html#sampling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_1d result_1d <<\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_1d = %sqlcmd snippets query_1d\n",
    "grading_util.save_results(\"result_1d\", query_1d, result_1d)\n",
    "result_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "\n",
    "# Question 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `movie_sample` table contains a very minimal amount of information per movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql SELECT * FROM movie_sample LIMIT 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we’re going to create a nice, refined view of the `movie_sample` table that also includes a **rating field**, called `movie_ratings`.\n",
    "\n",
    "The [MPAA rating](https://www.motionpictures.org/film-ratings/) is commonly included in most datasets about movies, including ours, but in its current format in the dataset, it’s quite difficult to extract.\n",
    "\n",
    "The first clue about our approach comes from the random rows you explored in Question 1. As you saw, the `movie_info_sample` table contains a lot of information about each movie. Each row contains a particular type of information (e.g., runtime, languages) categorized by `info_type_id`. Based on the other tables in this database, the `info_type` table is a reference table to this \n",
    "ID number.\n",
    "\n",
    "Our strategy in this question is therefore as follows:\n",
    "* **Question 2a**: Find the `mpaa_rating_id` from the `info_type` table.\n",
    "* **Question 2b**: Extract the MPAA rating of a specific movie from the `movie_info_sample` table.\n",
    "* **Question 2c**: Construct a view `movie_ratings` based on the `movie_sample` table and all relevant MPAA ratings extracted from the `movie_info_sample` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2a: MPAA Rating and `info_type`\n",
    "\n",
    "To start, using the `info_type` table, write a query to find which `id` corresponds to a film's MPAA rating.  The query `result_2a` that you write should return a relation with exactly one row and two attributes; the lone value in the instance should be the MPAA rating id number. In other words, your output table should look like this:\n",
    "\n",
    "| id | info |\n",
    "| :--- | :--- |\n",
    "| SOME_INTEGER_HERE | SOME_STRING_HERE |\n",
    "\n",
    "\n",
    "We've then assigned `mpaa_rating_id` to extract the number itself from the relation.\n",
    "\n",
    "**Before you get started**:\n",
    "- Open the `psql` client in a terminal to explore the schema of `info_type` via the `\\d` metacommand (see the [Assignment Tips](https://data101.org/fa25/assignment-tips/) page).\n",
    "- Remember you can also write SQL commands to that terminal to interact with the IMDB database, but all final work must be submitted through this Jupyter Notebook. We recommend selecting everything from the `info_type` table to see what the data looks like. Which row corresponds to the MPAA rating?\n",
    "\n",
    "**Hints:** \n",
    "- Be careful when using quotes. SQL interprets single and double quotes differently. The single quote character `'` is reserved for delimiting string constants, while the double quote `\"` is used for naming tables or columns that require special characters. See the [Postgres documentation](https://www.postgresql.org/docs/current/sql-syntax-lexical.html#SQL-SYNTAX-STRINGS) for more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_2a result_2a <<\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_2a = %sqlcmd snippets query_2a\n",
    "grading_util.save_results(\"result_2a\", query_2a, result_2a)\n",
    "mpaa_rating_id = result_2a[0][0]\n",
    "display(result_2a)\n",
    "mpaa_rating_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2b: Looking up the MPAA Rating\n",
    "\n",
    "Suppose we wanted to find the MPAA rating for the 2004 American teen drama classic, _Mean Girls_. The below cell assigns `movie_id_2b` to the IMDb ID of this movie, `2109683`. Then we select the `movie_sample` data for that movie ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell, no further action is needed.\n",
    "movie_id_2b = 2109683\n",
    "%sql SELECT * FROM movie_sample WHERE id = {{movie_id_2b}};"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the next cell, **write a query to find the MPAA rating for this movie.** Your query should return a relation with exactly one row , which has columns `(info, mpaa_rating)`, where `info` is the full MPAA rating string from `movie_info_sample`, and `mpaa_rating` is just the rating itself (i.e. `R`, `PG-13`, `PG`, etc) for this movie. In other words, your output table should look like this:\n",
    "\n",
    "| info | mpaa_rating |\n",
    "| :--- | :--- |\n",
    "| SOME_STRING_HERE | SOME_STRING_HERE |\n",
    "\n",
    "\n",
    "**Before you get started**:\n",
    "\n",
    "Explore the `movie_info_sample` tuples corresponding to the MPAA rating by using metacommands in the terminal. The `info` field is a little longer than just the rating. It also includes an explanation for why that movie received its rating. \n",
    "\n",
    "**Hints:**\n",
    "* You will need to extract a substring from the `info` column of `movie_info_sample`; you can use the [string functions](https://www.postgresql.org/docs/current/functions-string.html) in PostgreSQL to do it. There are many possible solutions.\n",
    "    * One possible solution is to use the `SUBSTRING` function along with regex. If you use this approach, [this section on regex](https://www.postgresql.org/docs/current/functions-matching.html#FUNCTIONS-POSIX-REGEXP) may be particularly useful.\n",
    "    * Also remember that `SUBSTRING` is 1-indexed, not 0-indexed. With your chosen approach, ensure that you are returning a single element, and not an array! You may also index into an array.\n",
    "    * [regex101.com](https://regex101.com) may additionally be helpful in crafting your regular expressions.\n",
    "* You may use `mpaa_rating_id` (from question 2a) and `movie_id_2b` (from the code cell above) directly in the rest of the questions using Python variable substitution (i.e., using double curly braces like in the code cell above). See the `JupySQL` documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_2b result_2b << \n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_2b = %sqlcmd snippets query_2b\n",
    "grading_util.save_results(\"result_2b\", query_2b, result_2b)\n",
    "result_2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You may use `mpaa_rating_id` directly in the rest of the questions using python variable substitution.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 2c\n",
    "In the next cell,\n",
    "1. Construct a view named `movie_ratings` containing one row for each movie, which has columns `(movie_id, title, info, mpaa_rating)`, where `info` is the full MPAA rating string from `movie_info_sample`, and `mpaa_rating` is just the rating itself (i.e. `R`, `PG-13`, `PG`, etc).\n",
    "    * In other words, extend `movie_sample` with the MPAA rating attributes that you found in the previous question part, but this time for all movies instead of just one movie.      \n",
    "2. Following the view definition, also write a `SELECT` query to return the **first 20 rows** of the view, ordered by ascending `movie_id`. Your table header should look like this:\n",
    "\n",
    "| movie_id | title | info | mpaa_rating |\n",
    "| -------- | ----- | ---- | ----------- |\n",
    "\n",
    "**Note:**\n",
    "* There will be some edge cases when the `info` column doesn't follow the pattern that you used in question 2b. Do not worry as long as you extract most of the ratings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_2c result_2c << \n",
    "DROP VIEW IF EXISTS movie_ratings;\n",
    "CREATE VIEW movie_ratings AS\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_2c = %sqlcmd snippets query_2c\n",
    "grading_util.save_results(\"result_2c\", query_2c, result_2c)\n",
    "result_2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 3: Movie Moola\n",
    "One measure of a movie's success is how much money it makes. If we look at our `info_type` table, we have information about the film's gross earnings and the budget for a film. It would be nice to know how much money a film made using the profit formula:\n",
    "$$profit = grossearnings - moneyspent$$\n",
    "\n",
    "We start by taking a look at the gross earnings info type (called `gross` in the `info_type` table), with `info_type_id = 107`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM movie_info_sample\n",
    "WHERE info_type_id = 107\n",
    "ORDER BY id\n",
    "LIMIT 10 OFFSET 100000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "There are a lot of things to notice here. First of all, the values in the `info` attribute are **strings** with not only the **earnings**, but also the **country** and the **month the earnings are cummulatively summed until**.\n",
    "\n",
    "Additionally, the info values are **not all in the same currency**! On top of that, it appears as if **some** of the gross earnings (even for those in USD) are **from worldwide sales**, while **others only count sales within the USA**.\n",
    "\n",
    "For consistency, let's only use movies with **gross earnings counted in the USA** and that are **in US Dollars ($)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a: Earnings\n",
    "We want the numerical part of the `info` column and the **MAXIMUM earnings value** for a particular film. \n",
    "\n",
    "In the next cell,\n",
    "- Construct a view named `movie_gross` containing **one row for each movie**, which has columns `(gross, movie_id, title)`, where `gross` is the numeric dollar amount of the **MAXIMUM earnings value** extracted as a float.\n",
    "- To take a look at our cleaned data that we just created in our `movie_gross` view, write a `SELECT` query to display the **top 10 highest grossing films** from `movie_gross`. This query should occur in the same cell and should **ONLY** list your limited top 10 output. Do not use `GROUP BY` or other aggregate functions outside of your view. Your column header should look like this:\n",
    "\n",
    "| gross | movie_id | title |\n",
    "| ----- | -------- | ----- |\n",
    "\n",
    "**Hints:** \n",
    "- The way we extracted the MPAA rating in question 2b is very similar to how we want to extract the substring containing the number and isolate the numeric dollar amount as a string. There are multiple ways of doing this.\n",
    "   - Look at the [course notes for `REGEXP_REPLACE`](https://data101.org/notes/1-SQL/strings.html#regexp-replace), specifically the `'g'` flag.\n",
    "   - Look at the [course notes for `SUBSTRING`](https://data101.org/notes/1-SQL/strings.html#advanced-string-functionality)\n",
    "- Be careful when trying to match IDs from one relation to another relation. Take a look at the schema of the relations you are working with, whether in terminal or by referring to the description at the top of the notebook. Ensure both fields reference the same entity. For example, `movie_info_sample.id` does **NOT** refer to the same entity as `movie_sample.id`.\n",
    "- Movies may have the same name! What attribute(s) to uniquely identifies a movie? Check the schema of `movie_sample`\n",
    "- The staff solution found it helpful to make a CTE to create the view. You may make as many CTEs as you find necessary.\n",
    "\n",
    "**Reminders:**\n",
    "- We will only be using movies with gross earnings counted in the **USA** and that are in US Dollars (**$**). Ensure that your `info` string contains both of these markers. The `info` string contains reported gross earnings as `(non-USA)` AND `(USA)`, so please check that you are not adding extraneous values.\n",
    "    - Look at the [course notes for the `LIKE` keyword](https://data101.org/notes/1-SQL/strings.html#like-not-like).\n",
    "- We are looking at the gross earnings info type (called `gross` in the `info_type` table), with `info_type_id = 107`. Other `info_type_id` values correspond to different information about movies that are not relevant for this question.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "While it is fine to add CTEs, do <b>NOT</b> create additional <em>views</em> as this may take up significant space in memory. If your kernel is crashing repeatedly, check that you are not creating any views in memory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM movie_info_sample\n",
    "WHERE info_type_id = 107\n",
    "AND info LIKE '%(USA)%'\n",
    "ORDER BY id\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_3a result_3a <<\n",
    "\n",
    "DROP VIEW IF EXISTS movie_gross CASCADE;\n",
    "CREATE VIEW movie_gross AS\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_3a = %sqlcmd snippets query_3a\n",
    "grading_util.save_results(\"result_3a\", query_3a, result_3a)\n",
    "result_3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Tutorial: Budget\n",
    "We will now look at the `budget` info type, with `info_type_id = 105`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * \n",
    "FROM movie_info_sample\n",
    "WHERE info_type_id = 105\n",
    "ORDER BY id\n",
    "LIMIT 10 OFFSET 5000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to when we examined the gross info, we see a lot of non-US dollar currencies. For consistency, let's only use movies **with a budget in US dollars.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 3b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now, we want something similar for the budget of the film, so that we can perform the subtraction of `gross` and `budget`. We want the numerical part of the `info` column and the **MAXIMUM budget value** for a particular film (as you can verify, some movies have more than one budget). \n",
    "\n",
    "In the next cell,\n",
    "- Construct a view named `movie_budget` containing one row for each movie, which has `(budget, movie_id, title)`, where `budget` is the numeric dollar amount extracted as a float.\n",
    "- To take a look at our cleaned data, write a `SELECT` query to display the **top 10 highest budget films** from `movie_budget`. When multiple films have the same budget, break ties by `movie_id` (ascending). Your column header should look like this:\n",
    "\n",
    "| budget | movie_id | title |\n",
    "| ------ | -------- | ----- |\n",
    "\n",
    "**Hint:** The query here should be quite similar to Question 3a. Make sure to break ties properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_3b result_3b <<\n",
    "\n",
    "DROP VIEW IF EXISTS movie_budget CASCADE;\n",
    "CREATE VIEW movie_budget AS\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_3b = %sqlcmd snippets query_3b\n",
    "grading_util.save_results(\"result_3b\", query_3b, result_3b)\n",
    "result_3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3c\n",
    "\n",
    "We now have all the parts we need to calculate the profits. Using the `movie_gross` and `movie_budget` views created above, we can now subtract the numeric columns and save the result in another column called `profit`.\n",
    "\n",
    "In the next cell, construct a view named `movie_profit` containing one row for each movie, which has columns `(movie_id, title, profit)`, where `profit` is the result of subtracting that movie's `budget` from `gross`.\n",
    "\n",
    "After the view definition, write a `SELECT` query to return the **first 10 rows** of the view ordered by descending `profit`. This may take a while to execute. Your column header should look like:\n",
    "\n",
    "| movie_id | title | profit |\n",
    "| -------- | ----- | ------ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_3c result_3c <<\n",
    "\n",
    "DROP VIEW IF EXISTS movie_profit;\n",
    "CREATE VIEW movie_profit AS\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_3c = %sqlcmd snippets query_3c\n",
    "grading_util.save_results(\"result_3c\", query_3c, result_3c)\n",
    "result_3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3d\n",
    "\n",
    "We analyzed the data, but something seems odd. Upon closer look, there are many negative values for `profit`. For example, the movie `102 Dalmatians` looks to have lost around $18M, but it was a widely successful film! What may account for this issue? Think about how we constrained our data from the start of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 4: Using Cleaned Data\n",
    "\n",
    "Now that we have cleaned our monetary records from the `info` attribute in `movie_info_sample`, let's take a closer look at the data we generated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4a: Analyzing Gross Earnings\n",
    "\n",
    "A common way to view numerical data is with a boxplot. A boxplot shows a spread of the data along with several other key attributes that allow for further data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We went through a lot of work transforming the gross earnings from strings in the`info` attribute into a numerical value. Because of our hard work, we can now further examine this data and understand its distribution. To do this, we first need to generate a [five-number summary](https://en.wikipedia.org/wiki/Five-number_summary) **and** find the average of the US gross earnings data.\n",
    "\n",
    "- Create a view named `earnings_summary`, which consists of a one row summary of the `movie_gross` `gross` data with the `min`, `25th_percentile`, `median`, `75th_percentile`, `max`, and `average`. \n",
    "- Following the view definition, write a `SELECT` query to display it. Your query result should look like this:\n",
    "\n",
    "| min | 25th_percentile | median | 75th_percentile | max | average |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| SOME_FLOAT_HERE | SOME_FLOAT_HERE | SOME_FLOAT_HERE | SOME_FLOAT_HERE | SOME_FLOAT_HERE | SOME_FLOAT_HERE |\n",
    "\n",
    "**Hint:** Look at SQL [aggregate functions](https://www.postgresql.org/docs/9.4/functions-aggregate.html). You may find some useful. Also, to ensure your answer matches the autograder, **please use `percentile_cont` instead of `percentile_dis`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "select *\n",
    "from movie_gross\n",
    "where gross = 2136381;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_4a result_4a <<\n",
    "\n",
    "DROP VIEW IF EXISTS earnings_summary CASCADE;\n",
    "CREATE VIEW earnings_summary AS\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_4a = %sqlcmd snippets query_4a\n",
    "grading_util.save_results(\"result_4a\", query_4a, result_4a)\n",
    "result_4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 4b\n",
    "What do you notice about the summary values generated in `earnings_summary`? We can represent the five-number summary graphically using a [box plot](https://en.wikipedia.org/wiki/Box_plot). Identify two properties about the boxplot of the data. (You do not need to explicitly create a boxplot, but think about how the summary statistics would be distributed in a boxplot.)\n",
    "\n",
    "**Hint:** Think in terms of about concepts from statistics like spread, modality, skew, etc. and how they may apply here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# optional: include your plotting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "<hr style=\"border: 1px solid #fdb515;\" />\n",
    "\n",
    "# Question 5: Joins\n",
    "\n",
    "Joins are a powerful tool in database cleaning and analysis. They allow for the user to create useful tables and bring together information in a meaningful way. \n",
    "\n",
    "There are many types of joins: inner, outer, left, right, etc. Let's practice these in a special scenario. \n",
    "\n",
    "You are now working as a talent director and you need a list of all people who have been in the role `actor`, **NOT** `actress`, and the number of **roles** they have acted. Of note, the original IMDB data maintains an antiquated gender binary in their encoding of roles that is not necessarily reflective of individuals' true genders.\n",
    "\n",
    "- Create a view called `number_roles`, which has columns `id`, `name`, `number` where `id` is the actor's id, `name` is the actor's name, and `number` is the number of roles they have acted.\n",
    "- Following your view, write a ``SELECT`` query to display the **top 10 actors** with the highest number of roles. Your column header should look like this:\n",
    "\n",
    "| id | name | number |\n",
    "| -- | ---- | ------ |\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- We recommend first exploring the `role_type` table in the terminal. Which `id` in the `role_type` corresponds to an actor?\n",
    "- Ignore the `gender` column in `actor_sample`. Instead, use the role id to determine if a person is an actor or actress.\n",
    "- The `cast_sample` may include actors not included in `actor_sample` table. We still want to include these actors in our result by reference to their `id`.\n",
    "- The `name` field can be `NULL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%sql --save query_5 result_5 <<\n",
    "\n",
    "DROP VIEW IF EXISTS number_roles;\n",
    "CREATE VIEW number_roles AS \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Do not delete/edit this cell!\n",
    "# You must run this cell before running the autograder.\n",
    "query_5 = %sqlcmd snippets query_5\n",
    "grading_util.save_results(\"result_5\", query_5, result_5)\n",
    "result_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border: 5px solid #003262;\" />\n",
    "<hr style=\"border: 1px solid #fdb515;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations! You have finished Project 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to zip and download the results of your queries. You will also need to run the export cell at the end of the notebook.\n",
    "\n",
    "**Please save your notebook before exporting (this is a good time to do it!)** Otherwise, we may not be able to register your written responses.\n",
    "\n",
    "**For your submission on Gradescope, you will need to submit the `proj1.zip` file generated by the export cell.** Please ensure that your submission includes `proj1.pdf`, `proj1.ipynb`, and `results.zip`. \n",
    "\n",
    "**Please ensure that public tests pass upon submission.** It is your responsibility to wait until the autograder finishes running. We will not be accepting regrade requests for submission issues.\n",
    "\n",
    "**Common submission issues:** You MUST submit the generated zip file to the autograder. However, Safari is known to automatically unzip files upon downloading. You can fix this by going into Safari preferences, and deselect the box with the text \"Open safe files after downloading\" under the \"General\" tab. If you experience issues with downloading via clicking on the link, you can also navigate to the project 1 directory within JupyterHub (remove `proj1.ipynb` from the url), and manually download the generated zip files. Please post on Ed if you encounter any other submission issues.\n",
    "\n",
    "Run the following cell to zip and download the results of your queries. You will also need to run the export cell at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grading_util.prepare_submission_and_cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(files=['results.zip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0": {
     "name": "q0",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_0, result_0_df = grading_util.load_results('result_0')\n>>> result_0_df.shape\n(6, 12)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_0, result_0_df = grading_util.load_results('result_0')\n>>> result_0_df['table_schema'][0]\n'public'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(result_1a)\n4",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> 'movie_id' in result_1a\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_1b, result_1b_df = grading_util.load_results('result_1b')\n>>> result_1b_df.shape\n(1, 1)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_1b, result_1b_df = grading_util.load_results('result_1b')\n>>> bool(2400000 <= result_1b_df.iloc[0, 0] <= 2450000)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_1b, result_1b_df = grading_util.load_results('result_1b')\n>>> bool(0.0001 <= p_1c <= 0.001)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_1c, result_1c_df = grading_util.load_results('result_1c')\n>>> 'BERNOULLI' in query_1c_str.upper()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1d": {
     "name": "q1d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_1d, result_1d_df = grading_util.load_results('result_1d')\n>>> result_1d_df.shape\n(5, 4)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_1d, result_1d_df = grading_util.load_results('result_1d')\n>>> list(result_1d_df.columns)\n['id', 'movie_id', 'info_type_id', 'info']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_1d, result_1d_df = grading_util.load_results('result_1d')\n>>> 'RANDOM' in query_1d.upper()\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_2a, result_2a_df = grading_util.load_results('result_2a')\n>>> result_2a_df.iloc[0, 0]\nnp.int64(97)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_2b, result_2b_df = grading_util.load_results('result_2b')\n>>> result_2b_df.shape\n(1, 2)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2b, result_2b_df = grading_util.load_results('result_2b')\n>>> result_2b_df['info'][0]\n'Rated PG-13 for sexual content, language and some teen partying'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2b, result_2b_df = grading_util.load_results('result_2b')\n>>> result_2b_df['mpaa_rating'][0]\n'PG-13'",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2c": {
     "name": "q2c",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df.shape\n(20, 4)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> list(result_2c_df.columns)\n['movie_id', 'title', 'info', 'mpaa_rating']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df['movie_id'][0]\nnp.int64(1632926)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df.set_index('movie_id').loc[1632926]['title']\n'$5 a Day'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df.set_index('movie_id').loc[1632926]['info']\n'Rated PG-13 for sexual content, brief nudity and language'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df.set_index('movie_id').loc[1632926]['mpaa_rating']\n'PG-13'",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_2c, result_2c_df = grading_util.load_results('result_2c')\n>>> result_2c_df['movie_id'].iloc[:10].sum()\nnp.int64(16333796)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_3a, result_3a_df = grading_util.load_results('result_3a')\n>>> result_3a_df.shape\n(10, 3)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3a, result_3a_df = grading_util.load_results('result_3a')\n>>> list(result_3a_df.columns)\n['gross', 'movie_id', 'title']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3a, result_3a_df = grading_util.load_results('result_3a')\n>>> result_3a_df['title'].iloc[:10]\n0                                        Avatar\n1                                       Titanic\n2                                  The Avengers\n3                               The Dark Knight\n4                                     Star Wars\n5                         The Dark Knight Rises\n6                                       Shrek 2\n7                    E.T. the Extra-Terrestrial\n8     Star Wars: Episode I - The Phantom Menace\n9    Pirates of the Caribbean: Dead Man's Chest\nName: title, dtype: object",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3a, result_3a_df = grading_util.load_results('result_3a')\n>>> result_3a_df['gross'].iloc[:5].sum()\nnp.float64(3038331946.0)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3a, result_3a_df = grading_util.load_results('result_3a')\n>>> result_3a_df['gross'][2]\nnp.float64(623357910.0)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_3b, result_3b_df = grading_util.load_results('result_3b')\n>>> result_3b_df.shape\n(10, 3)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3b, result_3b_df = grading_util.load_results('result_3b')\n>>> list(result_3b_df.columns)\n['budget', 'movie_id', 'title']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3b, result_3b_df = grading_util.load_results('result_3b')\n>>> result_3b_df['title'].iloc[:5]\n0    Pirates of the Caribbean: At World's End\n1                                     Tangled\n2                                Spider-Man 3\n3      Harry Potter and the Half-Blood Prince\n4                                 John Carter\nName: title, dtype: object",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3b, result_3b_df = grading_util.load_results('result_3b')\n>>> result_3b_df['budget'].iloc[:5].sum()\nnp.float64(1318000000.0)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_3c, result_3c_df = grading_util.load_results('result_3c')\n>>> result_3c_df.shape\n(10, 3)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3c, result_3c_df = grading_util.load_results('result_3c')\n>>> result_3c_df['title'].iloc[:5]\n0                        Avatar\n1                       Titanic\n2                     Star Wars\n3    E.T. the Extra-Terrestrial\n4                  The Avengers\nName: title, dtype: object",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_3c, result_3c_df = grading_util.load_results('result_3c')\n>>> result_3c_df['profit'].iloc[:5].sum()\nnp.float64(2260084056.0)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_4a, result_4a_df = grading_util.load_results('result_4a')\n>>> result_4a_df.shape\n(1, 6)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_4a, result_4a_df = grading_util.load_results('result_4a')\n>>> list(result_4a_df.columns)\n['min', '25th_percentile', 'median', '75th_percentile', 'max', 'average']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_4a, result_4a_df = grading_util.load_results('result_4a')\n>>> result_4a_df['median'].loc[0]\nnp.float64(2317091.0)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> query_5, result_5_df = grading_util.load_results('result_5')\n>>> result_5_df.shape\n(10, 3)",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_5, result_5_df = grading_util.load_results('result_5')\n>>> list(result_5_df.columns)\n['id', 'name', 'number']",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_5, result_5_df = grading_util.load_results('result_5')\n>>> result_5_df['name'].iloc[:5]\n0        Barker, Bob\n1    Freeman, Morgan\n2      Hinnant, Skip\n3       Trebek, Alex\n4         Sajak, Pat\nName: name, dtype: object",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> query_5, result_5_df = grading_util.load_results('result_5')\n>>> result_5_df['number'].iloc[:5].sum()\nnp.int64(26115)",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
